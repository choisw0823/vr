#!/usr/bin/env python3
"""
Easy R1 ì²´í¬í¬ì¸íŠ¸(.pt)ë¥¼ HuggingFace í˜•ì‹(.safetensors)ìœ¼ë¡œ ë³€í™˜
"""

import torch
import os
import argparse
from safetensors.torch import save_file
import json
from pathlib import Path


def convert_r1_checkpoint_to_hf(checkpoint_dir, output_dir=None):
    """
    R1 ì²´í¬í¬ì¸íŠ¸ë¥¼ HuggingFace í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    Args:
        checkpoint_dir: R1 ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ (global_step_XXX)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ checkpoint_dir/actor/huggingface ì‚¬ìš©)
    """
    
    checkpoint_dir = Path(checkpoint_dir)
    
    # ì…ë ¥ íŒŒì¼ ê²½ë¡œ
    pt_file = checkpoint_dir / "actor" / "model_world_size_1_rank_0.pt"
    hf_config_dir = checkpoint_dir / "actor" / "huggingface"
    
    if not pt_file.exists():
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pt_file}")
    
    if not hf_config_dir.exists():
        raise FileNotFoundError(f"HuggingFace ì„¤ì • ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {hf_config_dir}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if output_dir is None:
        output_dir = hf_config_dir
    else:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {pt_file}")
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {pt_file.stat().st_size / 1024**3:.2f} GB")
    
    # PyTorch ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    print("\nğŸ”„ PyTorch ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì¤‘...")
    try:
        checkpoint = torch.load(pt_file, map_location='cpu')
        print("âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise
    
    # ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° í™•ì¸
    print(f"\nğŸ“¦ ì²´í¬í¬ì¸íŠ¸ í‚¤: {list(checkpoint.keys())}")
    
    # state_dict ì¶”ì¶œ
    if 'module' in checkpoint:
        state_dict = checkpoint['module']
        print("âœ… 'module' í‚¤ì—ì„œ state_dict ì¶”ì¶œ")
    elif 'model' in checkpoint:
        state_dict = checkpoint['model']
        print("âœ… 'model' í‚¤ì—ì„œ state_dict ì¶”ì¶œ")
    elif isinstance(checkpoint, dict) and any(k.startswith('model.') for k in checkpoint.keys()):
        state_dict = checkpoint
        print("âœ… ì§ì ‘ state_dict ì‚¬ìš©")
    else:
        state_dict = checkpoint
        print("âš ï¸  ì²´í¬í¬ì¸íŠ¸ë¥¼ state_dictë¡œ ì§ì ‘ ì‚¬ìš©")
    
    # í‚¤ ì´ë¦„ ì •ë¦¬ (module. ì ‘ë‘ì‚¬ ì œê±° ë“±)
    cleaned_state_dict = {}
    for key, value in state_dict.items():
        # module. ì ‘ë‘ì‚¬ ì œê±°
        clean_key = key.replace('module.', '')
        # _orig_mod. ì ‘ë‘ì‚¬ ì œê±° (torch.compile ì‚¬ìš©ì‹œ)
        clean_key = clean_key.replace('_orig_mod.', '')
        cleaned_state_dict[clean_key] = value
    
    print(f"\nğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {len(cleaned_state_dict)}")
    print(f"ğŸ“Š ìƒ˜í”Œ í‚¤ë“¤:")
    for i, key in enumerate(list(cleaned_state_dict.keys())[:5]):
        print(f"  - {key}: {cleaned_state_dict[key].shape}")
    
    # safetensors í˜•ì‹ìœ¼ë¡œ ì €ì¥
    print(f"\nğŸ’¾ safetensors í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
    
    # ëª¨ë¸ í¬ê¸° í™•ì¸í•˜ì—¬ ë¶„í•  í•„ìš” ì—¬ë¶€ íŒë‹¨ (5GB ì´ìƒì´ë©´ ë¶„í• )
    total_size = sum(param.numel() * param.element_size() for param in cleaned_state_dict.values())
    total_size_gb = total_size / 1024**3
    
    print(f"ğŸ“Š ì´ ëª¨ë¸ í¬ê¸°: {total_size_gb:.2f} GB")
    
    if total_size_gb > 4.5:  # 5GBë³´ë‹¤ ì•½ê°„ ì‘ê²Œ ì„¤ì •
        print("âš ï¸  ëª¨ë¸ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. 3ê°œ íŒŒì¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤...")
        save_sharded_model(cleaned_state_dict, output_dir)
    else:
        print("ğŸ“¦ ë‹¨ì¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤...")
        safetensors_path = output_dir / "model.safetensors"
        save_file(cleaned_state_dict, safetensors_path)
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {safetensors_path}")
    
    print(f"\nâœ¨ ë³€í™˜ ì™„ë£Œ!")
    print(f"ğŸ“ HuggingFace ì²´í¬í¬ì¸íŠ¸ ìœ„ì¹˜: {output_dir}")
    print(f"\nì‚¬ìš©ë²•:")
    print(f"  model_path = '{output_dir}'")


def save_sharded_model(state_dict, output_dir):
    """í° ëª¨ë¸ì„ ì—¬ëŸ¬ íŒŒì¼ë¡œ ë¶„í•  ì €ì¥"""
    
    # íŒŒë¼ë¯¸í„°ë¥¼ 3ê°œ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
    keys = list(state_dict.keys())
    num_shards = 3
    shard_size = len(keys) // num_shards
    
    weight_map = {}
    
    for shard_idx in range(num_shards):
        start_idx = shard_idx * shard_size
        if shard_idx == num_shards - 1:
            end_idx = len(keys)
        else:
            end_idx = (shard_idx + 1) * shard_size
        
        shard_keys = keys[start_idx:end_idx]
        shard_dict = {k: state_dict[k] for k in shard_keys}
        
        # íŒŒì¼ ì´ë¦„
        shard_filename = f"model-{shard_idx+1:05d}-of-{num_shards:05d}.safetensors"
        shard_path = output_dir / shard_filename
        
        # ì €ì¥
        save_file(shard_dict, shard_path)
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {shard_filename} ({len(shard_keys)} íŒŒë¼ë¯¸í„°)")
        
        # weight_mapì— ì¶”ê°€
        for key in shard_keys:
            weight_map[key] = shard_filename
    
    # index.json ìƒì„±
    index = {
        "metadata": {
            "total_size": sum(param.numel() * param.element_size() for param in state_dict.values())
        },
        "weight_map": weight_map
    }
    
    index_path = output_dir / "model.safetensors.index.json"
    with open(index_path, 'w') as f:
        json.dump(index, f, indent=2)
    
    print(f"âœ… ì¸ë±ìŠ¤ íŒŒì¼ ìƒì„±: {index_path}")


def main():
    parser = argparse.ArgumentParser(description='R1 ì²´í¬í¬ì¸íŠ¸ë¥¼ HuggingFace í˜•ì‹ìœ¼ë¡œ ë³€í™˜')
    parser.add_argument('--checkpoint_dir', 
                       default='/home/work/smoretalk/seo/reranking/r1/checkpoints/easy_r1_msrvtt/qwen2_5_vl_3b_msrvtt_grpo_exp2/global_step_1000',
                       help='R1 ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ (global_step_XXX)')
    parser.add_argument('--output_dir', 
                       default=None,
                       help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: checkpoint_dir/actor/huggingface)')
    
    args = parser.parse_args()
    
    print("ğŸš€ R1 ì²´í¬í¬ì¸íŠ¸ ë³€í™˜ ì‹œì‘\n")
    
    try:
        convert_r1_checkpoint_to_hf(args.checkpoint_dir, args.output_dir)
    except Exception as e:
        print(f"\nâŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())

